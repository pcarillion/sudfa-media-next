import fs from 'fs'
import path from 'path'
import https from 'https'
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3'
import { 
  initializePayloadForMigration, 
  closePayloadConnections,
  logEnvironmentStatus 
} from './utils/migration-helpers'

// Configuration S3
const s3Client = new S3Client({
  region: 'eu-north-1',
  credentials: {
    accessKeyId: process.env.S3_ACCESS_KEY!,
    secretAccessKey: process.env.S3_SECRET_KEY!,
  },
})

const BUCKET_NAME = process.env.S3_BUCKET!

// Types pour les m√©dias
interface MediaDocument {
  id: string
  filename: string
  url: string
  alt?: string
  legend?: string
  mimeType?: string
  width?: number
  height?: number
  filesize?: number
  contentfulId?: string
  createdAt: string
  updatedAt: string
  // Champs Cloudinary possibles
  cloudinary?: {
    url?: string
    secure_url?: string
    public_id?: string
    version?: string
    resource_type?: string
    format?: string
  }
  // Autres champs possibles
  [key: string]: any
}

// Fonction utilitaire pour t√©l√©charger un fichier depuis une URL
async function downloadFile(url: string): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    https.get(url, (response) => {
      if (response.statusCode !== 200) {
        reject(new Error(`HTTP ${response.statusCode}: ${response.statusMessage}`))
        return
      }

      const chunks: Buffer[] = []
      response.on('data', (chunk) => chunks.push(chunk))
      response.on('end', () => resolve(Buffer.concat(chunks)))
      response.on('error', reject)
    }).on('error', reject)
  })
}

// Fonction pour uploader vers S3
async function uploadToS3(buffer: Buffer, key: string, contentType: string): Promise<string> {
  const command = new PutObjectCommand({
    Bucket: BUCKET_NAME,
    Key: `payload/${key}`,
    Body: buffer,
    ContentType: contentType,
  })

  await s3Client.send(command)
  return `https://${BUCKET_NAME}.s3.eu-north-1.amazonaws.com/payload/${key}`
}

// Fonction pour d√©terminer le Content-Type
function getContentType(filename: string): string {
  const ext = path.extname(filename).toLowerCase()
  const mimeTypes: Record<string, string> = {
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.png': 'image/png',
    '.gif': 'image/gif',
    '.webp': 'image/webp',
    '.svg': 'image/svg+xml',
    '.pdf': 'application/pdf',
    '.doc': 'application/msword',
    '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  }
  return mimeTypes[ext] || 'application/octet-stream'
}

// Fonction principale de migration
async function migrateMediaToS3() {
  console.log('üöÄ D√©but de la migration media ‚Üí media_s3...')
  
  // Afficher le statut des variables d'environnement
  logEnvironmentStatus()
  
  // Initialiser Payload avec les helpers (validation pour Cloudinary ET S3)
  const payload = await initializePayloadForMigration({
    isProduction: false,
    enablePush: false,
    useS3: false // On valide Cloudinary car on lit depuis media (Cloudinary)
  })

  // V√©rifier aussi les variables S3
  if (!process.env.S3_BUCKET || !process.env.S3_ACCESS_KEY || !process.env.S3_SECRET_KEY) {
    console.error('‚ùå Variables S3 manquantes (S3_BUCKET, S3_ACCESS_KEY, S3_SECRET_KEY)')
    process.exit(1)
  }

  console.log('‚úÖ Variables S3 v√©rifi√©es')
  console.log(`   - S3_BUCKET: ${process.env.S3_BUCKET}`)

  const stats = {
    processed: 0,
    skipped: 0,
    errors: 0
  }

  // Mapping entre anciens IDs (media) et nouveaux IDs (media_s3)
  const idMapping: Record<string, string> = {}

  try {
    // 1. Lire les m√©dias depuis le fichier JSON
    console.log('\nüìÅ Lecture des m√©dias depuis media.json...')
    
    const mediaJsonPath = path.join(process.cwd(), 'src/scripts/media.json')
    
    if (!fs.existsSync(mediaJsonPath)) {
      throw new Error(`Fichier media.json non trouv√© √†: ${mediaJsonPath}`)
    }
    
    const mediaData = JSON.parse(fs.readFileSync(mediaJsonPath, 'utf8'))
    console.log(`üìä ${mediaData.length} m√©dias trouv√©s dans media.json`)
    
    // Traiter tous les m√©dias (retirer .slice(0, 1) pour traiter tout)
    const mediaItems = { docs: mediaData }
    
    // Afficher le premier m√©dia pour debug
    if (mediaItems.docs.length > 0) {
      console.log('\nüîç PREMIER M√âDIA DU JSON:')
      console.log(JSON.stringify(mediaItems.docs[0], null, 2))
    }

    // 2. V√©rifier quels m√©dias existent d√©j√† dans media_s3
    const existingS3Media = await payload.find({
      collection: 'media_s3',
      limit: 1000,
    })

    const existingS3Ids = new Set(existingS3Media.docs.map(doc => doc.id))
    console.log(`üìä ${existingS3Media.docs.length} m√©dias d√©j√† pr√©sents dans media_s3`)

    // 3. Migrer chaque m√©dia depuis le JSON
    for (const media of mediaItems.docs as MediaDocument[]) {
      try {
        // V√©rifier si le m√©dia existe d√©j√† dans media_s3
        if (existingS3Ids.has(media.id)) {
          console.log(`‚è≠Ô∏è  M√©dia d√©j√† migr√©: ${media.filename} (ID: ${media.id})`)
          stats.skipped++
          continue
        }

        console.log(`\nüîÑ Migration du m√©dia: ${media.filename} (ID: ${media.id})`)
        
        // Utiliser l'URL directement depuis le JSON (donn√©es brutes de la DB)
        if (!media.url) {
          console.log(`   ‚ùå Pas d'URL pour le m√©dia: ${media.filename}`)
          stats.errors++
          continue
        }
        
        let cleanUrl = media.url
        
        // Si l'URL contient des param√®tres, les supprimer
        if (cleanUrl.includes('?')) {
          cleanUrl = cleanUrl.split('?')[0]
          console.log(`   üîß URL nettoy√©e (param√®tres supprim√©s): ${media.url} ‚Üí ${cleanUrl}`)
        }
        
        console.log(`   ‚¨áÔ∏è  T√©l√©chargement depuis: ${cleanUrl}`)
        
        const buffer = await downloadFile(cleanUrl)
        
        // Cr√©er un fichier temporaire et laisser Payload g√©rer l'upload vers S3
        console.log(`   üíæ Cr√©ation dans media_s3 avec upload automatique vers S3`)
        
        const tempDir = path.join(process.cwd(), 'temp')
        if (!fs.existsSync(tempDir)) {
          fs.mkdirSync(tempDir, { recursive: true })
        }
        
        const tempFilePath = path.join(tempDir, media.filename)
        fs.writeFileSync(tempFilePath, buffer)
        
        try {
          // Laisser Payload cr√©er le m√©dia et uploader vers S3 automatiquement
          const uploadedMedia = await payload.create({
            collection: 'media_s3',
            data: {
              alt: media.alt || '',
              legend: media.legend || '',
              contentfulId: media.contentfulId,
            },
            filePath: tempFilePath,
          })
          
          console.log(`   ‚úÖ M√©dia cr√©√© avec ID: ${uploadedMedia.id}, URL: ${uploadedMedia.url}`)
          
          // Enregistrer le mapping ancien ID ‚Üí nouveau ID
          idMapping[media.id] = uploadedMedia.id
          console.log(`   üìù Mapping: ${media.id} ‚Üí ${uploadedMedia.id}`)
          
        } finally {
          // Nettoyer le fichier temporaire
          if (fs.existsSync(tempFilePath)) {
            fs.unlinkSync(tempFilePath)
          }
        }

        console.log(`   ‚úÖ M√©dia migr√© avec succ√®s: ${media.filename}`)
        stats.processed++
        
        // Pause entre les uploads pour √©viter la surcharge
        await new Promise(resolve => setTimeout(resolve, 100))
        
      } catch (error) {
        console.error(`   ‚ùå Erreur lors de la migration de ${media.filename}:`, error)
        stats.errors++
      }
    }

    // R√©sum√© final
    console.log('\nüéâ Migration termin√©e!')
    console.log(`üìä R√©sum√©:`)
    console.log(`   ‚úÖ M√©dias migr√©s: ${stats.processed}`)
    console.log(`   ‚è≠Ô∏è  M√©dias d√©j√† pr√©sents: ${stats.skipped}`)
    console.log(`   ‚ùå Erreurs: ${stats.errors}`)
    console.log(`   üìÅ Source: collection media (Cloudinary)`)
    console.log(`   üìÅ Destination: collection media_s3 (S3)`)

    // Sauvegarder les statistiques et le mapping
    const statsFile = path.join(process.cwd(), 'migration-media-to-s3-stats.json')
    fs.writeFileSync(statsFile, JSON.stringify({
      timestamp: new Date().toISOString(),
      stats,
      source: 'media (Cloudinary)',
      destination: 'media_s3 (S3)',
      bucket: BUCKET_NAME,
      idMapping
    }, null, 2))
    console.log(`üíæ Statistiques sauvegard√©es dans: ${statsFile}`)

    // Sauvegarder le mapping s√©par√©ment
    const mappingFile = path.join(process.cwd(), 'id-mapping-media-to-s3.json')
    fs.writeFileSync(mappingFile, JSON.stringify(idMapping, null, 2))
    console.log(`üíæ Mapping des IDs sauvegard√© dans: ${mappingFile}`)

  } catch (error) {
    console.error('‚ùå Erreur lors de la migration:', error)
    throw error
  } finally {
    // Fermer les connexions Payload
    await closePayloadConnections(payload)
  }
}

// Fonction de validation post-migration
async function validateMigration() {
  console.log('\nüîç Validation post-migration...')
  
  // Initialiser Payload
  const payload = await initializePayloadForMigration({
    isProduction: false,
    enablePush: false,
    useS3: false
  })

  try {
    // Compter les m√©dias dans chaque collection
    const mediaCount = await payload.find({
      collection: 'media',
      limit: 1,
    })

    const mediaS3Count = await payload.find({
      collection: 'media_s3',
      limit: 1,
    })

    console.log(`üìä Comparaison des collections:`)
    console.log(`   üìÅ media (Cloudinary): ${mediaCount.totalDocs} √©l√©ments`)
    console.log(`   üìÅ media_s3 (S3): ${mediaS3Count.totalDocs} √©l√©ments`)

    // V√©rifier quelques m√©dias S3
    const s3Sample = await payload.find({
      collection: 'media_s3',
      limit: 5,
    })

    console.log(`\n‚úÖ √âchantillon de m√©dias S3:`)
    s3Sample.docs.forEach((media: any) => {
      console.log(`   - ${media.filename} (ID: ${media.id}): ${media.url}`)
    })

    // Lire le mapping si il existe
    const mappingFile = path.join(process.cwd(), 'id-mapping-media-to-s3.json')
    if (fs.existsSync(mappingFile)) {
      const mapping = JSON.parse(fs.readFileSync(mappingFile, 'utf8'))
      console.log(`\nüìã Mapping des IDs (${Object.keys(mapping).length} correspondances):`)
      Object.entries(mapping).slice(0, 5).forEach(([oldId, newId]) => {
        console.log(`   ${oldId} ‚Üí ${newId}`)
      })
      if (Object.keys(mapping).length > 5) {
        console.log(`   ... et ${Object.keys(mapping).length - 5} autres`)
      }
    }

    console.log(`\n‚úÖ Migration r√©ussie !`)
    console.log(`   - Les m√©dias sont stock√©s sur S3`)
    console.log(`   - Les URLs sont g√©n√©r√©es dynamiquement par l'adapteur`)
    console.log(`   - Le mapping des IDs est disponible dans id-mapping-media-to-s3.json`)

  } finally {
    // Fermer les connexions
    await closePayloadConnections(payload)
  }
}

// Script principal
async function main() {
  const args = process.argv.slice(2)
  
  if (args.includes('--validate')) {
    await validateMigration()
  } else {
    await migrateMediaToS3()
    await validateMigration()
  }
  
  process.exit(0)
}

// Ex√©cution directe du script
main().catch((error) => {
  console.error('‚ùå Erreur fatale:', error)
  process.exit(1)
})

export { migrateMediaToS3, validateMigration }